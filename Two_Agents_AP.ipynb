{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqrpaHWYXRW5"
      },
      "outputs": [],
      "source": [
        "#Must be one of:\n",
        "# 'Psychology'\n",
        "# 'WorldHistory'\n",
        "# 'Physics'\n",
        "# 'Biology'\n",
        "SUBJECT = 'Physics' #@param\n",
        "\n",
        "subject_to_doc_id = {}\n",
        "subject_to_doc_id['Psychology'] = '17vjXh3MucBnA9IFxTtm2FyAoL_k5XUse5rRFkT8SVxY'\n",
        "subject_to_doc_id['WorldHistory'] = '1vkLGb6lRwXnwc02uj2FFKqCr-GMpG7x7yXLw6IyWHLQ'\n",
        "subject_to_doc_id['Biology'] = '1POzciVHbgzgMgn8-wvRVtMdF3yV2nPEnFChKMlxRUKA'\n",
        "subject_to_doc_id['Physics'] = '1kbbxPWiMLO8BIq5DodlIa_x_ShcD2u6HwUSjgPLSKMU'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfhmRI0OX_j_",
        "outputId": "52c9c8eb-49f7-493b-a246-0f917ee3e3c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of questions: 12\n"
          ]
        }
      ],
      "source": [
        "# @title Read QAs from Google doc and store in `all_question_answers` variable\n",
        "\n",
        "# Import necessary libraries\n",
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "import base64\n",
        "import requests\n",
        "import re\n",
        "import json\n",
        "\n",
        "# Authenticate to access Google Docs API\n",
        "auth.authenticate_user()\n",
        "service = build('docs', 'v1')\n",
        "\n",
        "# Function to get document content\n",
        "def get_doc_content(doc_id):\n",
        "    doc = service.documents().get(documentId=doc_id).execute()\n",
        "    elements = doc['body']['content']\n",
        "    output = []\n",
        "\n",
        "    for element in elements:\n",
        "      if 'paragraph' in element:\n",
        "          for para_element in element['paragraph']['elements']:\n",
        "              if 'textRun' in para_element:\n",
        "                  output.append(para_element['textRun']['content'])\n",
        "                  #print(para_element['textRun']['content'])\n",
        "              else:\n",
        "                if 'inlineObjectElement' in para_element:\n",
        "                  #print(\"YES\")\n",
        "                  inline_object_id = para_element['inlineObjectElement']['inlineObjectId']\n",
        "                  inline_object = doc['inlineObjects'][inline_object_id]\n",
        "                  image_uri = inline_object['inlineObjectProperties']['embeddedObject']['imageProperties']['contentUri']\n",
        "                  image_response = requests.get(image_uri)\n",
        "                  base64_image = base64.b64encode(image_response.content).decode()\n",
        "                  output.append(\"\\n\"+base64_image)\n",
        "    return output\n",
        "\n",
        "def extract_numbers(input_string):\n",
        "    # Define the regular expression pattern\n",
        "    pattern = r\"Questions (\\d+)-(\\d+) refer to the following information\"\n",
        "\n",
        "    # Search for the pattern in the input string\n",
        "    match = re.search(pattern, input_string)\n",
        "\n",
        "    # If a match is found, extract and return the numbers\n",
        "    if match:\n",
        "        return int(match.group(1)), int(match.group(2))\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def parse_input(lines):\n",
        "    data = []\n",
        "    question, correct_answer = \"\", \"\"\n",
        "    question_started = False\n",
        "    start_q, end_q = 100000, 100000\n",
        "    common_info = \"\"\n",
        "    common_info_started = False\n",
        "    for line in lines:\n",
        "        #print(line)\n",
        "        if line.startswith(\"Correct Answer:\"):\n",
        "            # first non-whitespace character after ':'\n",
        "            correct_answer = line.split(\":\")[1].strip()[0]\n",
        "            data.append({\n",
        "              \"question\": question,\n",
        "              \"answer\": correct_answer\n",
        "            })\n",
        "            question = \"\"\n",
        "            correct_answer = \"\"\n",
        "            question_started = False\n",
        "        else:\n",
        "          # if line starts with number followed by '.'. Ex: \"13.\"\"\n",
        "          match = re.match(r'^(\\d+)\\.', line)\n",
        "          if match:\n",
        "            question_number = int(match.group(1))\n",
        "            if question_number >= start_q:\n",
        "              common_info_started = False\n",
        "            if common_info != \"\":\n",
        "              question = common_info + \"\\n\"\n",
        "            if question_number >= end_q:\n",
        "              common_info = \"\"\n",
        "              start_q, end_q = 100000, 100000\n",
        "            question += line[match.end():].strip()\n",
        "            question_started = True\n",
        "          elif question_started:\n",
        "            question += line\n",
        "          elif common_info_started:\n",
        "            common_info += line\n",
        "          else:\n",
        "            # common information to be used for next mutliple questions.\n",
        "            t = extract_numbers(line)\n",
        "            if t:\n",
        "              start_q, end_q = t\n",
        "              common_info_started = True\n",
        "              common_info = \"Answer the question in reference to the following information.\\n\"\n",
        "\n",
        "    if question_started:\n",
        "      data.append({\n",
        "          \"question\": question,\n",
        "          \"answer\": correct_answer\n",
        "      })\n",
        "    print(\"Number of questions: \" +str(len(data)))\n",
        "    return data\n",
        "\n",
        "def read_qa_from_doc(doc_id):\n",
        "  document_content = get_doc_content(doc_id)\n",
        "  return parse_input(document_content)\n",
        "\n",
        "def tokenize_and_replace_long_words(input_string, N=60):\n",
        "    \"\"\"\n",
        "    Tokenizes the input string and replaces words longer than N characters with an empty string.\n",
        "\n",
        "    Args:\n",
        "    input_string (str): The input string to be tokenized.\n",
        "    N (int): The maximum length of a word before it gets replaced.\n",
        "\n",
        "    Returns:\n",
        "    (str, set): A tuple containing the modified string and a set of replaced words.\n",
        "    \"\"\"\n",
        "\n",
        "    # Tokenizing the input string by splitting at spaces\n",
        "    tokens = input_string.split()\n",
        "\n",
        "    # Initializing an empty set to store the replaced words\n",
        "    replaced_words = set()\n",
        "\n",
        "    # Processing each token\n",
        "    for i, token in enumerate(tokens):\n",
        "        if len(token) > N:\n",
        "            input_string = input_string.replace(token, \"\")\n",
        "            replaced_words.add(token)\n",
        "\n",
        "    return input_string, replaced_words\n",
        "\n",
        "# Example usage of the function\n",
        "#example_string = \"This is an example sentence with some longwordsincluded for testing\"\n",
        "#modified_string, replaced_words = tokenize_and_replace_long_words(example_string, 5)\n",
        "#print(modified_string, replaced_words)\n",
        "\n",
        "if SUBJECT in subject_to_doc_id.keys():\n",
        "  all_question_answers = read_qa_from_doc(subject_to_doc_id[SUBJECT])\n",
        "else:\n",
        "  print(\"** Set SUBJECT variable **\")\n",
        "  all_question_answers = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dR1L8ZAFIE9M",
        "outputId": "ada25f8d-44af-4f3f-86b3-60b268f5241b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regarding meiosis and mitosis, one difference between the two forms of cellular reproduction is that in meiosis\n",
            "A. there is one round of cell division, whereas in mitosis there are two rounds of cell division\n",
            "B. separation of sister chromatids occurs during the second division, whereas in mitosis separation of sister chromatids occurs during the first division\n",
            "C. chromosomes are replicated during interphase, whereas in mitosis chromosomes are replicated during prophase\n",
            "D. spindle fibers form during prophase, whereas in mitosis the spindle fibers form during metaphase\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title Debug reading of questions from Google doc\n",
        "# parse_input(get_doc_content('17vjXh3MucBnA9IFxTtm2FyAoL_k5XUse5rRFkT8SVxY'))\n",
        "print(all_question_answers[3]['question'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GpYPruKBByk"
      },
      "outputs": [],
      "source": [
        "# @title OpenAI setup and base Agent class\n",
        "# This will be extended to Examinee (who gives answer to question) and Examiner (who checks the answer).\n",
        "\n",
        "api_key = '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'\n",
        "openai_endpoint = 'https://api.openai.com/v1/chat/completions'\n",
        "\n",
        "import requests\n",
        "import re\n",
        "import time\n",
        "\n",
        "headers = {\n",
        "  \"Content-Type\": \"application/json\",\n",
        "  \"Authorization\": f\"Bearer {api_key}\"\n",
        "}\n",
        "\n",
        "class Agent:\n",
        "  _num_choices = None\n",
        "  _debug = False\n",
        "\n",
        "  def __init__(self, num_choices):\n",
        "    self._num_choices = num_choices\n",
        "\n",
        "  def system_prompt(self):\n",
        "    raise NotImplementedError(\"Subclasses must implement this function.\")\n",
        "\n",
        "  def create_prompt(self, question):\n",
        "    raise NotImplementedError(\"Subclasses must implement this function.\")\n",
        "\n",
        "  def call_llm_api(self, payload):\n",
        "    response = requests.post(openai_endpoint, headers=headers, json=payload).json()\n",
        "    if 'error' in response:\n",
        "      # Check if error due to rate limiting.\n",
        "      msg = response['error']['message']\n",
        "      if re.match(r'Rate limit reached for gpt-4-vision-preview in organization .* on tokens per min', msg):\n",
        "        print(\"Warning: TPM rate limit hit. Will sleep for a minute and then try again.\")\n",
        "        time.sleep(60)\n",
        "        response = requests.post(openai_endpoint, headers=headers, json=payload).json()\n",
        "      else:\n",
        "        print(\"Warning: \"+response)\n",
        "    elif self._debug:\n",
        "      print(response)\n",
        "    if 'choices' in response:\n",
        "      return response['choices'][0]['message']['content']\n",
        "    return None\n",
        "\n",
        "  def ask(self, question, debug):\n",
        "    self._debug = debug\n",
        "    text_prompt, image_prompt = self.create_prompt(question)\n",
        "    if debug:\n",
        "      print(\"system_prompt: \"+self.system_prompt())\n",
        "      print(\"text_prompt: \"+text_prompt)\n",
        "      print(\"image_prompt: \"+image_prompt)\n",
        "    contents = []\n",
        "    contents.append({'type': \"text\", 'text': f\"{text_prompt}\"})\n",
        "    if image_prompt != \"\":\n",
        "      contents.append({\n",
        "          'type': \"image_url\",\n",
        "          'image_url': {\n",
        "            'url': f\"data:image/jpeg;base64,{image_prompt}\"\n",
        "          }\n",
        "        })\n",
        "    model = \"gpt-4-1106-preview\" # \"gpt-4\", \"gpt-3.5-turbo\"\n",
        "    if image_prompt != \"\":\n",
        "      model = \"gpt-4-vision-preview\"\n",
        "    payload = {\n",
        "      \"model\": model,\n",
        "      \"messages\": [\n",
        "        {\n",
        "          \"role\": \"system\",\n",
        "          \"content\": self.system_prompt()\n",
        "        },\n",
        "        {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": contents\n",
        "        }\n",
        "      ],\n",
        "      \"max_tokens\": 1000\n",
        "    }\n",
        "\n",
        "    response = self.call_llm_api(payload)\n",
        "    if response:\n",
        "      return response, True\n",
        "    else:\n",
        "      return response, False\n",
        "\n",
        "def find_last(input_string, substring):\n",
        "    start = 0\n",
        "    last_pos = -1\n",
        "    while start < len(input_string):\n",
        "        pos = input_string.find(substring, start)\n",
        "        if pos != -1:\n",
        "            last_pos = pos\n",
        "            start = pos + 1\n",
        "        else:\n",
        "            break\n",
        "    return last_pos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TF3GYrn5Jska"
      },
      "outputs": [],
      "source": [
        "# @title Examinee class that gives the answer to a given question\n",
        "\n",
        "class ExamineePromptStrategy:\n",
        "  _subject = None\n",
        "  _num_choices = None\n",
        "  role_assignment = True\n",
        "  process_of_elimination = True\n",
        "  double_check_work = True\n",
        "  pay_attention_to_question = True\n",
        "\n",
        "  def __init__(self, subject, num_choices, role_assignment = True, process_of_elimination = True, double_check_work = True):\n",
        "    self._subject = subject\n",
        "    self._num_choices = num_choices\n",
        "    self.role_assignment = role_assignment\n",
        "    self.process_of_elimination = process_of_elimination\n",
        "    self.double_check_work = double_check_work\n",
        "\n",
        "  def output_format_instruction(self):\n",
        "    # specify format that the model should follow in its output.\n",
        "    alphabets = \"\"\n",
        "    match self._num_choices:\n",
        "      case 5:\n",
        "        alphabets = \"A, B, C, D, or E\"\n",
        "      case 4:\n",
        "        alphabets = \"A, B, C, or D\"\n",
        "      case _:\n",
        "        print(\"ERROR. Unexpected number of choices \" + self._num_choices)\n",
        "    return f\"\"\"Your response MUST contain:\n",
        "\n",
        "correct answer is: \"\"<insert letters {alphabets}>\"\"\n",
        "\"\"\"\n",
        "\n",
        "  def solution_strategy(self):\n",
        "    if self.process_of_elimination and self.double_check_work:\n",
        "      return \"\"\"\n",
        "You must:\n",
        "* Use process of elimination to arrive at the most-probable answer.\n",
        "* Double check your work.\n",
        "* Pay close attention to what is being asked. For example, differentiate whether the question asks for the main theme of a given passage or the evidence of something that the passage provides.\n",
        "\"\"\"\n",
        "    if self.process_of_elimination and self.pay_attention_to_question:\n",
        "      return \"\"\"\n",
        "You must:\n",
        "* Use process of elimination to arrive at the most-probable answer.\n",
        "* Read the question carefully to pick the best of the two most-probable answers.\n",
        "\"\"\"\n",
        "    if self.process_of_elimination:\n",
        "      return \"\\nYou must use process of elimination to arrive at the most-probable answer.\\n\"\n",
        "    if self.double_check_work:\n",
        "      return \"\\nYou must double check your work.\\n\"\n",
        "    return \"\"\n",
        "\n",
        "  def system_prompt(self):\n",
        "    if self.role_assignment:\n",
        "      prompt = f\"You are a very knowledgable teacher with decades of experience teaching {self._subject} in high school.\\n\"\n",
        "    else:\n",
        "      prompt = \"\"\n",
        "    prompt += f\"Answer the following multiple-choices question from AP {self._subject} exam.\\n\"\n",
        "    prompt += self.solution_strategy()\n",
        "    # Without this end-of-line character, model does not seem to following\n",
        "    # the instructions on output formatting.\n",
        "    prompt += \"\\n\"\n",
        "    return prompt+self.output_format_instruction()\n",
        "\n",
        "class Examinee(Agent):\n",
        "  def __init__(self, subject, num_choices):\n",
        "    super().__init__(num_choices)\n",
        "    self.prompt_strategy = ExamineePromptStrategy(subject,\n",
        "                                                   num_choices,\n",
        "                                                   role_assignment = True,\n",
        "                                                   process_of_elimination = True,\n",
        "                                                   double_check_work = True)\n",
        "\n",
        "  def system_prompt(self):\n",
        "    return self.prompt_strategy.system_prompt()\n",
        "\n",
        "  def create_prompt(self, question):\n",
        "    question_text, question_images = tokenize_and_replace_long_words(question)\n",
        "\n",
        "    text_prompt = f\"\"\"\n",
        "{question_text}\n",
        "\"\"\"\n",
        "    image_prompt = \"\"\n",
        "    if len(question_images) > 0:\n",
        "      for qimg in question_images:\n",
        "        image_prompt = qimg\n",
        "        break\n",
        "    return text_prompt, image_prompt\n",
        "\n",
        "  def extract_answer(self, response):\n",
        "    if self._debug:\n",
        "      print(\"Attempting to extract answer from: \"+response)\n",
        "    response_all_caps = response.upper()\n",
        "    answer_index = find_last(response_all_caps, \"CORRECT ANSWER\")\n",
        "\n",
        "    alphabet = []\n",
        "    match self._num_choices:\n",
        "      case 4:\n",
        "        alphabet = ['A', 'B', 'C', 'D']\n",
        "      case 5:\n",
        "        alphabet = ['A', 'B', 'C', 'D', 'E']\n",
        "      case _:\n",
        "        print(\"ERROR. Unexpected number of choices \" + self._num_choices)\n",
        "\n",
        "    if answer_index != -1:\n",
        "      #if count_substring(response_all_caps, \"CORRECT ANSWER\") > 1:\n",
        "      #  print(\"WARNING: \"+response)\n",
        "      # Look for the next occurrence of any of the characters 'A', 'B', 'C', 'D', 'E'\n",
        "      for i in range(answer_index + len(\"CORRECT ANSWER\"), len(response)):\n",
        "          if response[i] in alphabet:\n",
        "              return response[i]\n",
        "    else:\n",
        "      char = response[0]\n",
        "      if char in alphabet:\n",
        "        return char\n",
        "    return None\n",
        "\n",
        "  def ask(self, question, debug = False):\n",
        "    response, is_success = super().ask(question, debug)\n",
        "    if is_success:\n",
        "      answer = self.extract_answer(response)\n",
        "      if answer:\n",
        "        return answer, response, True\n",
        "      else:\n",
        "        return answer, response, False\n",
        "    else:\n",
        "      return None, response, False\n",
        "\n",
        "if SUBJECT == \"Psychology\":\n",
        "  examinee = Examinee(SUBJECT, 5)\n",
        "elif SUBJECT in ['WorldHistory', 'Biology', 'Physics']:\n",
        "  examinee = Examinee(SUBJECT, 4)\n",
        "else:\n",
        "  print(\"** Set SUBJECT variable **\")\n",
        "  examinee = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uStQipSICL-"
      },
      "outputs": [],
      "source": [
        "# @title Examiner class that checks whether the answer is correct given a question and examinee's answer\n",
        "\n",
        "class Examiner(Agent):\n",
        "  # store the examinee's answer.\n",
        "  _examinee_answer = None\n",
        "  _examinee_explanation = None\n",
        "  _subject = None\n",
        "\n",
        "  def __init__(self, subject, num_choices):\n",
        "    super().__init__(num_choices)\n",
        "    self._subject = subject\n",
        "\n",
        "  def system_prompt(self):\n",
        "    alphabets = \"\"\n",
        "    match self._num_choices:\n",
        "      case 5:\n",
        "        alphabets = \"A, B, C, D, or E\"\n",
        "      case 4:\n",
        "        alphabets = \"A, B, C, or D\"\n",
        "      case _:\n",
        "        print(\"ERROR. Unexpected number of choices \" + self._num_choices)\n",
        "    return f\"\"\"\n",
        "You are an outstanding high school {self._subject} teacher. Your task is to check student's answer to a multiple-choice question from {self._subject} exam.\n",
        "\n",
        "You will be provided the question, student's answer, and student's explanation for their answer.\n",
        "\n",
        "Note that the student can be wrong. DO NOT GET MISLED by student's explanation.\n",
        "\n",
        "If student's answer is correct, simply say \"CORRECT\". Otherwise, your response MUST contain:\n",
        "\n",
        "correct answer is: \"\"<insert letters ${alphabets}>\"\"\n",
        "\"\"\"\n",
        "\n",
        "  def create_prompt(self, question):\n",
        "    question_text, question_images = tokenize_and_replace_long_words(question)\n",
        "\n",
        "    text_prompt = f\"\"\"\n",
        "{question_text}\n",
        "\n",
        "Student's answer: {self._examinee_answer}\n",
        "Student's explanation:\n",
        "{self._examinee_explanation}\n",
        "\"\"\"\n",
        "    image_prompt = \"\"\n",
        "    if len(question_images) > 0:\n",
        "      for qimg in question_images:\n",
        "        image_prompt = qimg\n",
        "        break\n",
        "    return text_prompt, image_prompt\n",
        "\n",
        "  def extract_answer(self, response):\n",
        "    if self._debug:\n",
        "      print(\"Attempting to extract answer from: \"+response)\n",
        "    if(response.find(\"CORRECT\") != -1):\n",
        "      return self._examinee_answer\n",
        "    response_all_caps = response.upper()\n",
        "    answer_index = find_last(response_all_caps, \"CORRECT ANSWER\")\n",
        "\n",
        "    alphabet = []\n",
        "    match self._num_choices:\n",
        "      case 4:\n",
        "        alphabet = ['A', 'B', 'C', 'D']\n",
        "      case 5:\n",
        "        alphabet = ['A', 'B', 'C', 'D', 'E']\n",
        "      case _:\n",
        "        print(\"ERROR. Unexpected number of choices \" + self._num_choices)\n",
        "\n",
        "    if answer_index != -1:\n",
        "        #if count_substring(response_all_caps, \"CORRECT ANSWER\") > 1:\n",
        "        #  print(\"WARNING: \"+response)\n",
        "        # Look for the next occurrence of any of the characters 'A', 'B', 'C', 'D', 'E'\n",
        "        for i in range(answer_index + len(\"CORRECT ANSWER\"), len(response)):\n",
        "            if response[i] in alphabet:\n",
        "                return response[i]\n",
        "    else:\n",
        "      char = response[0]\n",
        "      if char in alphabet:\n",
        "        return char\n",
        "    return None\n",
        "\n",
        "  def check_answer(self, question, examinee_answer, examinee_explanation, debug = False):\n",
        "    self._examinee_answer = examinee_answer\n",
        "    self._examinee_explanation = examinee_explanation\n",
        "    response, is_success = super().ask(question, debug)\n",
        "    if is_success:\n",
        "      answer = self.extract_answer(response)\n",
        "      if answer:\n",
        "        return answer, True\n",
        "      else:\n",
        "        return answer, False\n",
        "    else:\n",
        "      return None, False\n",
        "\n",
        "if SUBJECT == \"Psychology\":\n",
        "  examiner = Examiner(SUBJECT, 5)\n",
        "elif SUBJECT in ['WorldHistory', 'Biology', 'Physics']:\n",
        "  examiner = Examiner(SUBJECT, 4)\n",
        "else:\n",
        "  print(\"** Set SUBJECT variable **\")\n",
        "  examiner = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKmzUKsOYZxT"
      },
      "outputs": [],
      "source": [
        "def get_final_answer(question, is_examinee_only = False, debug=False, correct_answer=None):\n",
        "  examinee_answer, examinee_explanation, is_success = examinee.ask(question, debug)\n",
        "  if not is_success:\n",
        "    print(\"Examinee failed\")\n",
        "    return \"\", False\n",
        "  elif is_examinee_only:\n",
        "    if correct_answer:\n",
        "      if examinee_answer != correct_answer:\n",
        "        print(\"WARNING \" + examinee_explanation)\n",
        "    return examinee_answer, True\n",
        "  print(\"examinee_answer: \" + examinee_answer)\n",
        "  examiner_answer, is_success = examiner.check_answer(question, examinee_answer, examinee_explanation, debug)\n",
        "  if not is_success:\n",
        "    print(\"Examiner failed\")\n",
        "    return \"\", False\n",
        "  print(\"examiner_answer: \" + examiner_answer)\n",
        "  return examiner_answer, True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpIxanzJxQnk",
        "outputId": "872b9c85-3838-4dd8-c8ef-4759fc7d03c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "system_prompt: You are a very knowledgable teacher with decades of experience teaching Biology in high school.\n",
            "Answer the following multiple-choices question from AP Biology exam.\n",
            "\n",
            "You must:\n",
            "* Use process of elimination to arrive at the most-probable answer.\n",
            "* Read the question carefully to pick the best of the two most-probable answers.\n",
            "\n",
            "Your response MUST contain:\n",
            "\n",
            "correct answer is: \"\"<insert letters A, B, C, or D>\"\"\n",
            "\n",
            "text_prompt: \n",
            "During the period when life is believed to have begun, the atmosphere on primitive Earth contained abundant amounts of all the following gases EXCEPT\n",
            "A. oxygen\n",
            "B. hydrogen\n",
            "C. ammonia\n",
            "D. methane\n",
            "\n",
            "\n",
            "\n",
            "image_prompt: \n",
            "{'id': 'chatcmpl-8gc2sZq9G7yImYhFP6XMLiC58b9C0', 'object': 'chat.completion', 'created': 1705166714, 'model': 'gpt-4-1106-preview', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': 'correct answer is: \"A\"'}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 142, 'completion_tokens': 7, 'total_tokens': 149}, 'system_fingerprint': 'fp_168383a679'}\n",
            "Attempting to extract answer from: correct answer is: \"A\"\n",
            "Final answer: A\n"
          ]
        }
      ],
      "source": [
        "# 7, 15, 22, 23, 24\n",
        "\n",
        "question = all_question_answers[11]['question']\n",
        "examinee.prompt_strategy.double_check_work = False\n",
        "examinee.prompt_strategy.process_of_elimination = True\n",
        "examinee.prompt_strategy.pay_attention_to_question = True\n",
        "final_answer, is_success = get_final_answer(question, is_examinee_only=True, debug=True)\n",
        "if is_success:\n",
        "  print(\"Final answer: \"+final_answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NN6P0cxjdkSa",
        "outputId": "2522939d-2bba-42cd-c3d8-41c29a99dded"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt configuration:\n",
            "double_check_work: False\n",
            "process_of_elimination: True\n",
            "pay_attention_to_question: True\n",
            "\n",
            "Question Number: 0\n",
            "ChatGpt answer: D\n",
            "Correct answer: D\n",
            "Question Number: 1\n",
            "WARNING To solve this question, we need to use the formula for the kinematic equation of motion for a uniformly accelerated object:\n",
            "\n",
            "\\( s = ut + \\frac{1}{2}at^2 \\)\n",
            "\n",
            "Where:\n",
            "- \\( s \\) is the displacement (5m down the incline)\n",
            "- \\( u \\) is the initial velocity (0 m/s, since the block is released from rest)\n",
            "- \\( a \\) is the acceleration\n",
            "- \\( t \\) is the time\n",
            "\n",
            "First, we need to find the acceleration \\( a \\) down the incline. Since the block is on an incline and the surface is frictionless, the only force that acts on the block is the component of the gravitational force along the incline, which is \\( mg\\sin(\\theta) \\), where \\( g \\) is the acceleration due to gravity (9.8 m/s^2) and \\( \\theta \\) is the angle of the incline. This force causes an acceleration \\( a \\), which can be found using Newton's second law:\n",
            "\n",
            "\\( f = ma \\)\n",
            "\n",
            "So, \\( a = \\frac{f}{m} = \\frac{mg\\sin(\\theta)}{m} = g\\sin(\\theta) \\)\n",
            "\n",
            "For \\( \\theta = 30^\\circ \\), \\( \\sin(30^\\circ) = 0.5 \\), hence \\( a = 9.8 \\times 0.5 = 4.9 \\text{ m/s}^2 \\).\n",
            "\n",
            "With this acceleration, the kinematic equation becomes:\n",
            "\n",
            "\\( 5 = 0 \\times t + \\frac{1}{2} \\times 4.9 \\times t^2 \\)\n",
            "\n",
            "This simplifies to:\n",
            "\n",
            "\\( 5 = 2.45t^2 \\)\n",
            "\n",
            "Dividing both sides by 2.45 gives:\n",
            "\n",
            "\\( t^2 = \\frac{5}{2.45} \\)\n",
            "\n",
            "\\( t^2 ≈ 2.0408 \\)\n",
            "\n",
            "Taking the square root of both sides to solve for \\( t \\) gives:\n",
            "\n",
            "\\( t ≈ √2.0408 \\)\n",
            "\n",
            "\\( t ≈ 1.428 \\) s\n",
            "\n",
            "Looking at the options provided, the closest value is:\n",
            "\n",
            "C. 1.4 s\n",
            "\n",
            "So, the correct answer is: \"C\"\n",
            "ChatGpt answer: C\n",
            "Correct answer: D\n",
            "Question Number: 2\n",
            "WARNING To solve this problem, we can use the conservation of energy principle. Since the surface of the incline is frictionless, we know that mechanical energy will be conserved. The block's potential energy at the top will be converted into kinetic energy at the bottom.\n",
            "\n",
            "The potential energy (PE) at the top is given by PE = mgh, where m is the mass, g is the acceleration due to gravity (9.8 m/s^2), and h is the height.\n",
            "\n",
            "From the diagram, we see that the height (h) can be calculated from the length of the incline (5 m) and the angle of inclination (30°) using trigonometry (h = 5 m * sin(30°)).\n",
            "\n",
            "Given:\n",
            "m = 0.5 kg\n",
            "g = 9.8 m/s²\n",
            "h = 5 m * sin(30°) = 5 m * 0.5 = 2.5 m\n",
            "\n",
            "PE = mgh = 0.5 kg * 9.8 m/s² * 2.5 m = 12.25 J\n",
            "\n",
            "This potential energy will be converted into kinetic energy (KE) at the bottom of the incline. The kinetic energy is given by KE = (1/2)mv², where v is the velocity we want to find.\n",
            "\n",
            "Since PE = KE (because energy is conserved), we can write:\n",
            "\n",
            "12.25 J = (1/2) * 0.5 kg * v²\n",
            "\n",
            "Now let's solve for v:\n",
            "\n",
            "v² = (2 * 12.25 J) / 0.5 kg ≈ 49\n",
            "v ≈ √49\n",
            "v ≈ 7 m/s\n",
            "\n",
            "None of the options match exactly, but among the given choices, 8 m/s (Option A) is the closest without exceeding the calculated speed. Remember, since the block starts from rest and accelerates under gravity alone, its speed must be less than or equal to the square root of 49 m/s (which is 7 m/s).\n",
            "\n",
            "The correct answer is: \"A\"\n",
            "ChatGpt answer: A\n",
            "Correct answer: B\n",
            "Question Number: 3\n",
            "ChatGpt answer: A\n",
            "Correct answer: A\n",
            "Question Number: 4\n",
            "ChatGpt answer: B\n",
            "Correct answer: B\n",
            "Question Number: 5\n",
            "ChatGpt answer: C\n",
            "Correct answer: C\n",
            "Question Number: 6\n",
            "ChatGpt answer: C\n",
            "Correct answer: C\n",
            "Question Number: 7\n",
            "ChatGpt answer: C\n",
            "Correct answer: C\n",
            "Question Number: 8\n",
            "ChatGpt answer: D\n",
            "Correct answer: D\n",
            "Question Number: 9\n"
          ]
        }
      ],
      "source": [
        "# @title Ask tutor every question in the dataset\n",
        "\n",
        "if False:\n",
        "  # Bio\n",
        "  # 98% (1 mistake)\n",
        "  # Physics 12 questions\n",
        "  # 75% (3 mistakes)\n",
        "  examinee.prompt_strategy.double_check_work = False\n",
        "  examinee.prompt_strategy.process_of_elimination = False\n",
        "  examinee.prompt_strategy.pay_attention_to_question = False\n",
        "else:\n",
        "  # History\n",
        "  # 96% (2 mistakes)\n",
        "  # 98% (1 mistakes)\n",
        "  # Bio\n",
        "  # 98% (1 mistake)\n",
        "  # Physics\n",
        "  # 58% (5 mistakes)\n",
        "  examinee.prompt_strategy.double_check_work = False\n",
        "  examinee.prompt_strategy.process_of_elimination = True\n",
        "  examinee.prompt_strategy.pay_attention_to_question = True\n",
        "\n",
        "print(\"Prompt configuration:\")\n",
        "print(\"double_check_work: \" + str(examinee.prompt_strategy.double_check_work))\n",
        "print(\"process_of_elimination: \" + str(examinee.prompt_strategy.process_of_elimination))\n",
        "print(\"pay_attention_to_question: \" + str(examinee.prompt_strategy.pay_attention_to_question))\n",
        "print()\n",
        "\n",
        "num_correct = 0\n",
        "num_total = 0\n",
        "num_failures = 0\n",
        "question_number = 0\n",
        "for qa in all_question_answers:\n",
        "  print(\"Question Number: \" + str(question_number))\n",
        "  llm_answer, is_success = get_final_answer(qa['question'], is_examinee_only=True, debug=False, correct_answer=qa['answer'])\n",
        "  print('ChatGpt answer: '+ llm_answer)\n",
        "  print('Correct answer: '+qa['answer'])\n",
        "  if is_success:\n",
        "    if llm_answer[0] == qa['answer']:\n",
        "      num_correct += 1\n",
        "  else:\n",
        "    num_failures += 1\n",
        "  num_total += 1\n",
        "  question_number += 1\n",
        "precision = 100*(num_correct / num_total)\n",
        "print(f\"Precision: {precision}% ({num_correct}/{num_total})\")\n",
        "print(f\"Number of failures: {num_failures}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwJoPzHObx_3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9d8hpQYO05s",
        "outputId": "f25cea23-2cdc-464d-d385-97cfe80941d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s = \" A. \"\n",
        "type(s.strip()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "RQZ1dmx284g8",
        "outputId": "545a426b-1959-40f1-f607-51ff0a9ec7bd"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-2c5b5563f432>\"\u001b[0;36m, line \u001b[0;32m20\u001b[0m\n\u001b[0;31m    \"content\": tutor.system_prompt()t\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
          ]
        }
      ],
      "source": [
        "best_prompt = \"\"\"\n",
        "  1. Provide the most accurate answer to the question.\n",
        "  2. Do not rush to the answer. Think step by step. Go through the definitions of mentioned terms thoroughly and check with multiple sources whenever possible.\n",
        "  3. If there are any commonly made mistakes or misconceptions related to this question, please identify and make sure to not fall for them.\n",
        "  4. Re-check your answer, go through the proccess again and ensure you end up with the same final answer.\n",
        "  5. It is of utmost important that your response ends with \"Final answer: \" \"\"insert letters A, B, C, D, E here\"\"\n",
        "\"\"\"\n",
        "best_accuracy = 86\n",
        "\n",
        "text_prompt = \"I am creating a tool that gives users the correct answers to multiple choice AP Questions. The tool utilizes ChaptGPT 4 Turbo (you) to get these correct answers. I need to generate the perfect prompt to ask chat gpt to maximize the accuracy. Here is the current best prompt YOU have generated in the past times I have called you through this API. Prompt: \" + best_prompt + \"This prompt's accuracy was \" + best_accuracy + \". Please now generate a new prompt that will you think improve the accuracy. DO NOT OUTPUT ANY ADDITIONAL TEXT IN EXPLANATION OR RESPONDING AS YOUR OUTPUT WILL DIRCETLY BE COPIED AND USED AS THE PROMPT FOR THE API QUERY.\"\n",
        "\n",
        "contents = []\n",
        "contents.append({'type': \"text\", 'text': f\"{text_prompt}\"})\n",
        "\n",
        "payload = {\n",
        "  \"model\": \"gpt-4-vision-preview\",\n",
        "  \"messages\": [\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": tutor.system_prompt()t\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": contents\n",
        "\n",
        "    }\n",
        "  ],\n",
        "  \"max_tokens\": 1000\n",
        "}\n",
        "\n",
        "response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload).json()\n",
        "prompt = ['choices'][0]['message']['content']\n",
        "\n",
        "# for i in range(20):\n",
        "\n",
        "#     text_prompt = \"I am creating a tool that gives users the correct answers to multiple choice AP Questions. The tool utilizes ChaptGPT 4 Turbo (you) to get these correct answers. I need to generate the perfect prompt to ask chat gpt to maximize \"\n",
        "\n",
        "#     contents = []\n",
        "#     contents.append({'type': \"text\", 'text': f\"{text_prompt}\"})\n",
        "\n",
        "#     payload = {\n",
        "#       \"model\": \"gpt-4-vision-preview\",\n",
        "#       \"messages\": [\n",
        "#         {\n",
        "#           \"role\": \"system\",\n",
        "#           \"content\": self.system_prompt()\n",
        "#         },\n",
        "#         {\n",
        "#           \"role\": \"user\",\n",
        "#           \"content\": contents\n",
        "\n",
        "#         }\n",
        "#       ],\n",
        "#       \"max_tokens\": 1000\n",
        "#     }\n",
        "\n",
        "#     response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload).json()\n",
        "#     prompt = ['choices'][0]['message']['content']\n",
        "\n",
        "#   num_correct = 0\n",
        "#   num_total = 0\n",
        "#   num_failures = 0\n",
        "#   question_number = 0\n",
        "\n",
        "#   for qa in all_question_answers:\n",
        "#     print(\"Question Number\" + str(question_number))\n",
        "#     llm_answer, is_success = tutor.ask(qa['question'], False, False)\n",
        "#     print('ChatGpt answer: '+ llm_answer)\n",
        "#     print('Correct answer: '+qa['answer'])\n",
        "#     if is_success:\n",
        "#       if llm_answer[0] == qa['answer']:\n",
        "#         num_correct += 1\n",
        "#     else:\n",
        "#       num_failures += 1\n",
        "#     num_total += 1\n",
        "#     question_number += 1\n",
        "\n",
        "#   precision = 100*(num_correct / num_total)\n",
        "\n",
        "#   if precision > best_precison:\n",
        "#     best_precision = precision\n",
        "#     best_prompt = curr_prompt"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}